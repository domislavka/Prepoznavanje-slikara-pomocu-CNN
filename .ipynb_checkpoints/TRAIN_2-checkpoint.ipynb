{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivana/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, Activation, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from shutil import copy\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103250, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    date     genre  pixelsx  pixelsy  size_bytes   source  \\\n",
       "0  Barnett Newman  1955.0  abstract  15530.0   6911.0   9201912.0  wikiart   \n",
       "1  Barnett Newman  1950.0  abstract  14559.0   6866.0   8867532.0  wikiart   \n",
       "2     kiri nichol  2013.0       NaN   9003.0   9004.0   1756681.0      NaN   \n",
       "3     kiri nichol  2013.0       NaN   9003.0   9004.0   1942046.0      NaN   \n",
       "4     kiri nichol  2013.0       NaN   9003.0   9004.0   1526212.0      NaN   \n",
       "\n",
       "                  style                  title artist_group  in_train  \\\n",
       "0  Color Field Painting                  Uriel   train_only      True   \n",
       "1  Color Field Painting  Vir Heroicus Sublimis   train_only      True   \n",
       "2         Neoplasticism                    NaN    test_only     False   \n",
       "3         Neoplasticism                    NaN    test_only     False   \n",
       "4         Neoplasticism                    NaN    test_only     False   \n",
       "\n",
       "  new_filename  \n",
       "0   102257.jpg  \n",
       "1    75232.jpg  \n",
       "2    32145.jpg  \n",
       "3    20304.jpg  \n",
       "4      836.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pogledamo podatke o SVIM slikama, one su spremljene u datoteci all_data_info.csv\n",
    "\n",
    "df = pd.read_csv(\"/home/ivana/repos/Vje-ba/all_data_info.csv\")\n",
    "# inicijalizirmo seed za random pozive\n",
    "seed = 123\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "(8476, 12)\n"
     ]
    }
   ],
   "source": [
    "############# TESTIRANJE RADI LI OVO: MAPA TRAIN_2 ###########################\n",
    "# threshold je granica koja određujemo kojeg ćemo autora uzeti,\n",
    "# odnosno koliko autor najmanje treba imati slika da ga uzmemo u obzir\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "# s ovom linijom dohvaćamo podtablicu koja se odnosi \n",
    "# na one slike koje pripadaju datoteci train_2\n",
    "df2 = df.loc[(df['in_train'] == True) & df['new_filename'].str.startswith('2')]\n",
    "# x2.head()\n",
    "\n",
    "# koliko uopće imamo autora u ovoj podtablici\n",
    "x2 = list(df2['artist'].value_counts())\n",
    "\n",
    "# koliko imamo autora s bar threshold slika\n",
    "print(len([a for a in x2 if a >= threshold]))\n",
    "\n",
    "# oblik tablice\n",
    "print(df2.shape)\n",
    "# df2.head()\n",
    "\n",
    "# nadalje, radimo sa df2 tablicom koju spremamo u df\n",
    "df=df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229\n"
     ]
    }
   ],
   "source": [
    "print(len([a for a in x2 if a <= 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autora s <= 10 slika ima 1229\n"
     ]
    }
   ],
   "source": [
    "# mali problem su slikari s jednom slikom, odnosno oni koji imaju manje od 10 slika\n",
    "small_artists = [a for a in x2 if a <= 10]\n",
    "print('Autora s <= 10 slika ima ' + str(len(small_artists)))\n",
    "\n",
    "# sljedeće linije su ostavljene zbog debuggiranja\n",
    "# tmp2 = df['artist'].value_counts()\n",
    "# small_artist_df = tmp2[tmp2 <= 10].index.tolist()\n",
    "# print(len(small_artist_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepoznajemo 87 slikara\n"
     ]
    }
   ],
   "source": [
    "# train, validation, test --- 80, 10, 10\n",
    "# num_train = threshold * 0.8\n",
    "num_train = 16       # num_val = threshold * 0.1\n",
    "num_val = 2          # num_test = num_val\n",
    "num_test = num_val\n",
    "num_samples = num_train + num_val + num_test   # num_samples = threshold\n",
    "\n",
    "# podtablica umjetnika koje ćemo promatrati\n",
    "temp = df['artist'].value_counts()\n",
    "# lista umjetnika koje ćemo promatrati\n",
    "artists = temp[temp >= threshold].index.tolist()\n",
    "#print(artists)\n",
    "num_artists = len(artists)\n",
    "print('Prepoznajemo ' + str(num_artists) + ' slikara')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepoznajemo 87 slikara\n",
      "train tablica\t\t (1392, 12)\n",
      "validation tablica\t (174, 12)\n",
      "test tablica\t\t (174, 12)\n"
     ]
    }
   ],
   "source": [
    "train_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "for a in artists:\n",
    "    \n",
    "    tmp = df[df['artist'].str.startswith(a)].sample(n=num_samples, random_state=seed)\n",
    "\n",
    "    t_df = tmp.sample(n = num_train, random_state=seed)\n",
    "    \n",
    "    rest_df = tmp.loc[~tmp.index.isin(t_df.index)] # uzmi komplement od t_df\n",
    "    \n",
    "    v_df = rest_df.sample(n = num_val, random_state=seed)\n",
    "    \n",
    "    te_df = rest_df.loc[~rest_df.index.isin(v_df.index)]\n",
    "    \n",
    "    train_dfs.append(t_df)\n",
    "    val_dfs.append(v_df)\n",
    "    test_dfs.append(te_df)\n",
    "    \n",
    "    # copyImagesToFiles(a, t_df, v_df, te_df)\n",
    "\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "val_df = pd.concat(val_dfs)\n",
    "test_df = pd.concat(test_dfs)\n",
    "\n",
    "print('train tablica\\t\\t', train_df.shape)\n",
    "print('validation tablica\\t', val_df.shape)\n",
    "print('test tablica\\t\\t', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, center_crop_size):\n",
    "    assert img.shape[2] == 3\n",
    "    centerw, centerh = img.shape[0] // 2, img.shape[1] // 2\n",
    "    halfw, halfh = center_crop_size[0] // 2, center_crop_size[1] // 2\n",
    "    return img[centerw-halfw:centerw+halfw, centerh-halfh:centerh+halfh, :]\n",
    "\n",
    "# https://jkjung-avt.github.io/keras-image-cropping/\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length, random_crop_bool=True):\n",
    "    '''\n",
    "    Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator\n",
    "    '''\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            if random_crop_bool == True:\n",
    "                batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "            else:\n",
    "                batch_crops[i] = center_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n",
    "\n",
    "\n",
    "# https://tutorials.technology/blog/02-Selecting-random-elements-from-list-using-python-Reservoir-Sampling-algorithm.html\n",
    "def select_k_random_elements_from(collection_iterator, k):\n",
    "    result = {}\n",
    "    n = 0\n",
    "\n",
    "    for item in collection_iterator:\n",
    "        n += 1\n",
    "        if len(result) < k:\n",
    "            result[n - 1] = item\n",
    "        else:\n",
    "            selected_index = int(random.random() * n)\n",
    "            if selected_index < k:\n",
    "                result[selected_index] = item\n",
    "    return result.values()\n",
    "\n",
    "def select_k_elements_from(collection_iterator, k, artist_index):\n",
    "    result = {}\n",
    "    n = 0\n",
    "\n",
    "    for index, item in collection_iterator:\n",
    "        n += 1\n",
    "        if len(result) < k:\n",
    "            result[n - 1] = item\n",
    "        else:\n",
    "            if item[0] == artist_index:\n",
    "                selected_index = index\n",
    "            if selected_index < k:\n",
    "                result[selected_index] = item\n",
    "    return result.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1392 images belonging to 87 classes.\n",
      "Found 174 images belonging to 87 classes.\n"
     ]
    }
   ],
   "source": [
    "# velicina slika koje dajemo ulaznom sloju mreze\n",
    "input_shape = (224, 224, 3)\n",
    "# velicina batch-a\n",
    "b_size = 87\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "                horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    '../train',\n",
    "                    batch_size=b_size,\n",
    "                    class_mode='categorical')\n",
    "train_generator = train_datagen.standardize(train_generator)\n",
    "\n",
    "# na slikama iz train skupa radimo crop na slučajnom mjestu\n",
    "train_crops = crop_generator(train_generator, 224)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "                    '../validation',\n",
    "                    batch_size=b_size,\n",
    "                    class_mode='categorical')\n",
    "validation_generator = val_datagen.standardize(validation_generator)\n",
    "\n",
    "# na slikama iz validation skupa radimo centralni crop\n",
    "val_crops = crop_generator(validation_generator, 224, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# početak ćelija za debuggiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 images belonging to 87 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                '../test',\n",
    "                target_size=(224, 224),\n",
    "                batch_size=87)\n",
    "\n",
    "num_artists = 87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  1  1  2  2  3  3  4  4  5  5  6  6  7  7  8  8  9  9 10 10 11 11\n",
      " 12 12 13 13 14 14 15 15 16 16 17 17 18 18 19 19 20 20 21 21 22 22 23 23\n",
      " 24 24 25 25 26 26 27 27 28 28 29 29 30 30 31 31 32 32 33 33 34 34 35 35\n",
      " 36 36 37 37 38 38 39 39 40 40 41 41 42 42 43 43 44 44 45 45 46 46 47 47\n",
      " 48 48 49 49 50 50 51 51 52 52 53 53 54 54 55 55 56 56 57 57 58 58 59 59\n",
      " 60 60 61 61 62 62 63 63 64 64 65 65 66 66 67 67 68 68 69 69 70 70 71 71\n",
      " 72 72 73 73 74 74 75 75 76 76 77 77 78 78 79 79 80 80 81 81 82 82 83 83\n",
      " 84 84 85 85 86 86]\n"
     ]
    }
   ],
   "source": [
    "print(test_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kraj ćelija za debuggiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 348)               2183004   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 348)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 87)                30363     \n",
      "=================================================================\n",
      "Total params: 2,223,767\n",
      "Trainable params: 2,223,639\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model mreže inspiriran glavnim člankom\n",
    "\n",
    "model = Sequential()\n",
    "#nn.Conv2d(3, 32, kernel_size=3 +, stride=2 +, padding=1), # -> 112\n",
    "model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\",input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32, kernel_size=3, strides=2, padding=\"same\", input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4*num_artists, input_shape=(6272,))) #nn.Linear(6272, 4*num_artists),\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_artists, input_shape=(4*num_artists,))) #nn.Linear(4*num_artists, num_artists)\n",
    "\n",
    "# koristimo adamov optimizator i metrika je točnost\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# crta tablicu slojeva mreže\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP_SIZE_TRAIN 16\n",
      "STEP_SIZE_VALID 2\n",
      "Epoch 1/3\n",
      "16/16 [==============================] - 234s 15s/step - loss: 8.6747 - acc: 0.0115 - val_loss: 8.0112 - val_acc: 0.0287\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 361s 23s/step - loss: 8.7536 - acc: 0.0151 - val_loss: 8.2387 - val_acc: 0.0345\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 356s 22s/step - loss: 8.7691 - acc: 0.0230 - val_loss: 8.3748 - val_acc: 0.0402\n"
     ]
    }
   ],
   "source": [
    "# treniramo mrežu....\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "print('STEP_SIZE_TRAIN', STEP_SIZE_TRAIN)\n",
    "print('STEP_SIZE_VALID', STEP_SIZE_VALID)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_crops,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "    epochs=3,\n",
    "    validation_data=val_crops,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    workers=4)\n",
    "\n",
    "model.save_weights('treci_pokusaj.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate_generator(test_generator,\n",
    "                         steps=test_generator.n//test_generator.batch_size,\n",
    "                         workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[8.244586706161499, 0.01149425283074379]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns\n",
    "\n",
    "Scalar test loss (if the model has a single output and no metrics) or list of scalars (if the model has multiple outputs and/or metrics). The attribute model.metrics_names will give you the display labels for the scalar outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                                      steps=test_generator.n//test_generator.batch_size,\n",
    "                                      workers=4,\n",
    "                                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174, 87)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "print(type(predictions))\n",
    "preds = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(preds == test_generator.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns\n",
    "\n",
    "Numpy array(s) of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iduće ćelije služe/služile su za debuggiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = PaintingFolder('home/ivana/data/images/train/', transform=None, df=train_df)\n",
    "val_dset = PaintingFolder('home/ivana/data/images/val/', transform=None, df=val_df)\n",
    "test_dset = PaintingFolder('home/ivana/data/images/test/', transform=None, df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dset[0])\n",
    "print(len(val_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "            horizontal_flip=True)\n",
    "\n",
    "train_x = []\n",
    "for img in val_dset:\n",
    "    temp_x = img_to_array(img[0])\n",
    "    temp_x = temp_x.reshape((1,)+temp_x.shape)\n",
    "    train_x.append(temp_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('train2-val.txt', 'w')\n",
    "for item in train_x:\n",
    "    thefile.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img('home/ivana/data/train_2/2.jpg')\n",
    "img2 = load_img('home/ivana/data/train_2/20.jpg')\n",
    "# img.show()\n",
    "x = img_to_array(img)\n",
    "# print(x.shape)\n",
    "x = x.reshape((1,)+x.shape)\n",
    "# print(x.shape)\n",
    "x2 = img_to_array(img2)\n",
    "x2 = x2.reshape((1,)+x2.shape)\n",
    "print('x2', x2.shape)\n",
    "X = [x, x2]\n",
    "\n",
    "\n",
    "train_batch = datagen.flow(X, batch_size=1)\n",
    "train_crops = crop_generator(train_batch, 224, False)\n",
    "\n",
    "batch_x, batch_y = next(train_crops)\n",
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "batch_x = batch_x.reshape(224, 224, 3)\n",
    "print(batch_x.shape)\n",
    "cropped_image = array_to_img(batch_x)\n",
    "cropped_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

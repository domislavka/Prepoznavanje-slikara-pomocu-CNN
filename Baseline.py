from __future__ import print_function
import warnings
from os import environ
from PIL import Image

Image.MAX_IMAGE_PIXELS = None
warnings.simplefilter('ignore', Image.DecompressionBombWarning)
environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

from keras.layers import Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D
from keras.layers import GlobalAveragePooling2D, AveragePooling2D, Input, Flatten, Activation, Dropout, Dense
from keras.optimizers import Adam, SGD
from keras.initializers import glorot_normal
from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard
from keras.callbacks import ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.regularizers import l2
from keras import backend as K
from keras.models import Sequential, Model
from keras.preprocessing import image
from os import path, getcwd


import pandas as pd
import random
import numpy as np
import shutil

def sve_jpg(df):
    for item in list(df.new_filename):
        if not '.jpg' in item:
            return False
    return True

def center_crop(img, center_crop_size):
    assert img.shape[2] == 3
    centerw, centerh = img.shape[0] // 2, img.shape[1] // 2
    halfw, halfh = center_crop_size[0] // 2, center_crop_size[1] // 2
    return img[centerw-halfw:centerw+halfw, centerh-halfh:centerh+halfh, :]

# https://jkjung-avt.github.io/keras-image-cropping/
def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]

def crop_generator(batches, crop_length, random_cropping=True, test_batch=False):
    '''
    Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator
    '''
    while True:
        if test_batch == False:
            batch_x, batch_y = next(batches)
        else:
            batch_x = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            if random_cropping == True:
                batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
            else:
                batch_crops[i] = center_crop(batch_x[i], (crop_length, crop_length))
        if test_batch == False:
            yield (batch_crops, batch_y)
        else:
            yield batch_crops

df = pd.read_csv(path.join(getcwd(), 'all_data_info.csv'))
seed = 123

print('Sve su jpg: ' + str(sve_jpg(df)))

threshold = 300

x = list(df['artist'].value_counts())

# train, validation, test --- 80%, 10%, 10%
num_train = 240
num_val = 30
num_test = num_val
num_samples = num_train + num_val + num_test
b_size = 60

#lista umjetnika koje ćemo promatrati
temp = df['artist'].value_counts()
artists = temp[temp >= threshold].index.tolist()

num_artists = len(artists)
print('Prepoznajemo ' + str(num_artists) + ' umjetnika')

# velicina slika koje dajemo ulaznom sloju mreze
input_shape = (224, 224, 3)
# velicina batch-a
b_size = 30

train_datagen = ImageDataGenerator(horizontal_flip=True)
val_datagen = ImageDataGenerator(horizontal_flip=True)
test_datagen = ImageDataGenerator()

train_generator = train_datagen.flow_from_directory(
                    '../train',
                    batch_size=b_size,
                    class_mode='categorical')
train_generator = train_datagen.standardize(train_generator)
# na slikama iz train skupa radimo crop na slučajnom mjestu
train_crops = crop_generator(train_generator, 224)

validation_generator = val_datagen.flow_from_directory(
                    '../validation',
                    batch_size=b_size,
                    class_mode='categorical')
# na slikama iz validation skupa radimo centralni crop
val_crops = crop_generator(validation_generator, 224, False)

test_generator = test_datagen.flow_from_directory(
                '../test',
                batch_size=b_size,
                class_mode=None, # this means our generator will only yield batches of data, no labels
                shuffle=False) # our data will be in order

test_crops = crop_generator(test_generator, 224, False, True)

# Model mreže
# (model mreže inspiriran glavnim člankom)

model = Sequential()
model.add(Conv2D(32,
                 kernel_size=3, 
                 strides=2, 
                 padding='same', 
                 input_shape=input_shape,
                 kernel_initializer=glorot_normal()))

model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=2))
model.add(Conv2D(32, 
                 kernel_size=3, 
                 strides=2, 
                 padding="same", 
                 input_shape=input_shape,
                 kernel_initializer=glorot_normal()))

model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=2))
model.add(Flatten())
model.add(Dense(4*num_artists, 
                input_shape=(6272,),
                kernel_initializer=glorot_normal()))
model.add(Activation('relu'))
model.add(Dense(num_artists, 
                input_shape=(4*num_artists,),
                activation='softmax',
                kernel_initializer=glorot_normal()))

tbCallBack = TensorBoard(log_dir='./GraphSiroviVgg16-3', 
                         write_graph=True, 
                         write_images=True,
                         write_grads=False)

mdCheckPoint = ModelCheckpoint(filepath='sirovi-vgg16.weights.{epoch:02d}--{val_acc:.5f}.hdf5',
                               monitor='val_acc',
                               mode='max',
                               save_best_only=False,
                               save_weights_only=False,
                               verbose=1,
                               period=1)

# koristimo adamov optimizator i metrika je točnost
model.compile(loss='categorical_crossentropy',
              optimizer=Adam(lr=1e-4),
              metrics=['accuracy'])

# crta tablicu slojeva mreže
model.summary()

# mrežu smo već istrenirali i spremili njene težine
# model.load_weights('pokusaj300-20.h5')

STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size
STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size

# treniramo mrežu....
model.fit_generator(train_crops,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    epochs=10,
                    validation_data=val_crops,
                    validation_steps=STEP_SIZE_VALID,
                    workers=4,
                    callbacks=[
                        TensorBoard(log_dir='./GraphBaseline', 
                                    histogram_freq=1, 
                                    write_graph=True, 
                                    write_images=True,
                                    write_grads=False),
                        ModelCheckpoint(filepath='baseline.weights.{epoch:02d}--{val_acc:.5f}.hdf5',
                                    monitor='val_acc',
                                    mode='max',
                                    save_best_only=False,
                                    save_weights_only=False,
                                    verbose=1,
                                    period=1)])

model.save_weights('prvi_pokusaj300SVE-SLIKE20.h5')

evaluation = model.evaluate_generator(test_crops,
                         steps=test_generator.n//test_generator.batch_size,
                         workers=4,
                         verbose=1)

print(model.metrics_names)
print(evaluation)

predictions = model.predict_generator(test_crops, 
                                      steps=test_generator.n//test_generator.batch_size,
                                      workers=4,
                                      verbose=1)

preds = np.argmax(predictions, axis=-1) # multiple categories

label_map = (train_generator.class_indices)
label_map = dict((v,k) for k,v in label_map.items()) # flip k,v
preds_names = [label_map[k] for k in preds]

print(sum(preds == test_generator.classes)/len(preds))
print(label_map)

np.save(open('predictions_base_test.npy', 'wb'), predictions)

img_path = 0
img = image.load_img("/home/ivana/repos/Vje-ba/testPicasso.jpg")
x = image.img_to_array(img)

print(type(img))
print(img.size)
img_cropped = center_crop(x, (224, 224))
img_cropped_blah = image.array_to_img(img_cropped)
img_cropped_blah.show()

x_pred = model.predict_classes(img_cropped.reshape(1, 224, 224, 3), batch_size=1)
print('Sliku je naslikao: ', label_map[x_pred[0]])

img1 = image.load_img("/home/ivana/repos/Vje-ba/testGogh.jpg")
x1 = image.img_to_array(img1)

print(type(img1))
img_cropped1 = center_crop(x1, (224, 224))
img_cropped_blah1 = image.array_to_img(img_cropped1)
img_cropped_blah1.show()

x_pred1 = model.predict_classes(img_cropped1.reshape(1, 224, 224, 3), batch_size=1)
print('Sliku je naslikao: ', label_map[x_pred1[0]])

from sklearn.metrics import classification_report, confusion_matrix

print(confusion_matrix(test_generator.classes, preds))
print(classification_report(test_generator.classes, preds))

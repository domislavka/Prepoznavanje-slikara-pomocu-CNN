{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "from os import environ\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "warnings.simplefilter('ignore', Image.DecompressionBombWarning)\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, Activation, Dropout, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sve_jpg(df):\n",
    "    for item in list(df.new_filename):\n",
    "        if not '.jpg' in item:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103250, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>date</th>\n",
       "      <th>genre</th>\n",
       "      <th>pixelsx</th>\n",
       "      <th>pixelsy</th>\n",
       "      <th>size_bytes</th>\n",
       "      <th>source</th>\n",
       "      <th>style</th>\n",
       "      <th>title</th>\n",
       "      <th>artist_group</th>\n",
       "      <th>in_train</th>\n",
       "      <th>new_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>15530.0</td>\n",
       "      <td>6911.0</td>\n",
       "      <td>9201912.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Uriel</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>102257.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barnett Newman</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>abstract</td>\n",
       "      <td>14559.0</td>\n",
       "      <td>6866.0</td>\n",
       "      <td>8867532.0</td>\n",
       "      <td>wikiart</td>\n",
       "      <td>Color Field Painting</td>\n",
       "      <td>Vir Heroicus Sublimis</td>\n",
       "      <td>train_only</td>\n",
       "      <td>True</td>\n",
       "      <td>75232.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1756681.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>32145.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1942046.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>20304.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kiri nichol</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9003.0</td>\n",
       "      <td>9004.0</td>\n",
       "      <td>1526212.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Neoplasticism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test_only</td>\n",
       "      <td>False</td>\n",
       "      <td>836.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist    date     genre  pixelsx  pixelsy  size_bytes   source  \\\n",
       "0  Barnett Newman  1955.0  abstract  15530.0   6911.0   9201912.0  wikiart   \n",
       "1  Barnett Newman  1950.0  abstract  14559.0   6866.0   8867532.0  wikiart   \n",
       "2     kiri nichol  2013.0       NaN   9003.0   9004.0   1756681.0      NaN   \n",
       "3     kiri nichol  2013.0       NaN   9003.0   9004.0   1942046.0      NaN   \n",
       "4     kiri nichol  2013.0       NaN   9003.0   9004.0   1526212.0      NaN   \n",
       "\n",
       "                  style                  title artist_group  in_train  \\\n",
       "0  Color Field Painting                  Uriel   train_only      True   \n",
       "1  Color Field Painting  Vir Heroicus Sublimis   train_only      True   \n",
       "2         Neoplasticism                    NaN    test_only     False   \n",
       "3         Neoplasticism                    NaN    test_only     False   \n",
       "4         Neoplasticism                    NaN    test_only     False   \n",
       "\n",
       "  new_filename  \n",
       "0   102257.jpg  \n",
       "1    75232.jpg  \n",
       "2    32145.jpg  \n",
       "3    20304.jpg  \n",
       "4      836.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/ivana/repos/Vje-ba/all_data_info.csv')\n",
    "seed = 123\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sve su jpg: True\n"
     ]
    }
   ],
   "source": [
    "print('Sve su jpg: ' + str(sve_jpg(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "threshold = 300\n",
    "\n",
    "x = list(df['artist'].value_counts())\n",
    "# broj umjetnika koji imaju vise ili jednako od 300 slika\n",
    "print(len([a for a in x if a >= threshold]))\n",
    "# len(set(x)) #---> ukupan broj umjetnika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepoznajemo 57 umjetnika\n"
     ]
    }
   ],
   "source": [
    "# train, validation, test --- 80, 10, 10\n",
    "num_train = 240\n",
    "num_val = 30\n",
    "num_test = num_val\n",
    "num_samples = num_train + num_val + num_test\n",
    "b_size = 60\n",
    "\n",
    "#lista umjetnika koje ćemo promatrati\n",
    "temp = df['artist'].value_counts()\n",
    "artists = temp[temp >= threshold].index.tolist()\n",
    "# print(artists)\n",
    "\n",
    "num_artists = len(artists)\n",
    "print('Prepoznajemo ' + str(num_artists) + ' umjetnika')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepoznajemo 57 umjetnika\n",
      "train tablica\t\t (13680, 12)\n",
      "validation tablica\t (1710, 12)\n",
      "test tablica\t\t (1710, 12)\n"
     ]
    }
   ],
   "source": [
    "train_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "for a in artists:\n",
    "    # PROVJERI KASNIJE ŠTA JE S NA=TRUE\n",
    "    tmp = df[df['artist'].str.startswith(a)].sample(n=num_samples, random_state=seed)\n",
    "    # print(tmp.shape)\n",
    "    t_df = tmp.sample(n=num_train, random_state=seed)\n",
    "    rest_df = tmp.loc[~tmp.index.isin(t_df.index)] # uzmi komplement od t_df\n",
    "    # print(rest_df.shape)\n",
    "    v_df = rest_df.sample(n=num_val, random_state=seed)\n",
    "    te_df = rest_df.loc[~rest_df.index.isin(v_df.index)]\n",
    "    \n",
    "    train_dfs.append(t_df)\n",
    "    val_dfs.append(v_df)\n",
    "    test_dfs.append(te_df)\n",
    "    \n",
    "    # ovo se pokrene samo jednom!!\n",
    "    copyImagesToFiles(a, t_df, v_df, te_df)\n",
    "\n",
    "train_df = pd.concat(train_dfs)\n",
    "val_df = pd.concat(val_dfs)\n",
    "test_df = pd.concat(test_dfs)\n",
    "\n",
    "print('train tablica\\t\\t', train_df.shape)\n",
    "print('validation tablica\\t', val_df.shape)\n",
    "print('test tablica\\t\\t', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, center_crop_size):\n",
    "    assert img.shape[2] == 3\n",
    "    centerw, centerh = img.shape[0] // 2, img.shape[1] // 2\n",
    "    halfw, halfh = center_crop_size[0] // 2, center_crop_size[1] // 2\n",
    "    return img[centerw-halfw:centerw+halfw, centerh-halfh:centerh+halfh, :]\n",
    "\n",
    "# https://jkjung-avt.github.io/keras-image-cropping/\n",
    "def random_crop(img, random_crop_size):\n",
    "    # Note: image_data_format is 'channel_last'\n",
    "    assert img.shape[2] == 3\n",
    "    height, width = img.shape[0], img.shape[1]\n",
    "    dy, dx = random_crop_size\n",
    "    x = np.random.randint(0, width - dx + 1)\n",
    "    y = np.random.randint(0, height - dy + 1)\n",
    "    return img[y:(y+dy), x:(x+dx), :]\n",
    "\n",
    "\n",
    "def crop_generator(batches, crop_length, random_cropping=True):\n",
    "    '''\n",
    "    Take as input a Keras ImageGen (Iterator) and generate random\n",
    "    crops from the image batches generated by the original iterator\n",
    "    '''\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            if random_cropping == True:\n",
    "                batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))\n",
    "            else:\n",
    "                batch_crops[i] = center_crop(batch_x[i], (crop_length, crop_length))\n",
    "        yield (batch_crops, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13680 images belonging to 57 classes.\n",
      "Found 1710 images belonging to 57 classes.\n",
      "Found 1710 images belonging to 57 classes.\n"
     ]
    }
   ],
   "source": [
    "# velicina slika koje dajemo ulaznom sloju mreze\n",
    "input_shape = (224, 224, 3)\n",
    "# velicina batch-a\n",
    "b_size = 30\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "                horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "                horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                    '../train',\n",
    "                    batch_size=b_size,\n",
    "                    class_mode='categorical')\n",
    "train_generator = train_datagen.standardize(train_generator)\n",
    "# na slikama iz train skupa radimo crop na slučajnom mjestu\n",
    "train_crops = crop_generator(train_generator, 224)\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "                    '../validation',\n",
    "                    batch_size=b_size,\n",
    "                    class_mode='categorical')\n",
    "# na slikama iz validation skupa radimo centralni crop\n",
    "val_crops = crop_generator(validation_generator, 224, False)\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                '../test',\n",
    "                target_size=(224, 224),\n",
    "                batch_size=b_size)\n",
    "test_crops = crop_generator(test_generator, 224, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model mreže"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 112, 112, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 228)               1430244   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 228)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 57)                13053     \n",
      "=================================================================\n",
      "Total params: 1,453,697\n",
      "Trainable params: 1,453,569\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model mreže inspiriran glavnim člankom\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=3, \n",
    "                 strides=2, \n",
    "                 padding='same', \n",
    "                 input_shape=input_shape,\n",
    "                 kernel_initializer=glorot_normal()))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=3, \n",
    "                 strides=2, \n",
    "                 padding=\"same\", \n",
    "                 input_shape=input_shape,\n",
    "                 kernel_initializer=glorot_normal()))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4*num_artists, \n",
    "                input_shape=(6272,),\n",
    "                kernel_initializer=glorot_normal()))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_artists, \n",
    "                input_shape=(4*num_artists,),\n",
    "                activation='softmax',\n",
    "                kernel_initializer=glorot_normal()))\n",
    "\n",
    "tbCallBack = TensorBoard(log_dir='./Graph300-5', \n",
    "                         histogram_freq=0, \n",
    "                         write_graph=True, \n",
    "                         write_images=True)\n",
    "\n",
    "# koristimo adamov optimizator i metrika je točnost\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# crta tablicu slojeva mreže\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  5/456 [..............................] - ETA: 27:54 - loss: 5.2070 - acc: 0.0400"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9f7e79eacb75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                     callbacks=[tbCallBack])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# treniramo mrežu....\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "model.fit_generator(train_crops,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_crops,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    workers=4,\n",
    "                    callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('prvi_pokusaj300SVE-SLIKE20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 97s 2s/step\n",
      "['loss', 'acc']\n",
      "[8.563225168930856, 0.027485381354365433]\n"
     ]
    }
   ],
   "source": [
    "evaluation = model.evaluate_generator(test_generator,\n",
    "                         steps=test_generator.n//test_generator.batch_size,\n",
    "                         workers=4,\n",
    "                         verbose=1)\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 83s 1s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(test_generator,\n",
    "                        steps=test_generator.n//test_generator.batch_size,\n",
    "                        workers=4,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ... False False False]\n",
      "1.4619883040935673\n",
      "[43 27 19 ... 19 19 12]\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(preds == test_generator.classes)\n",
    "LIST = preds == test_generator.classes\n",
    "print(sum(LIST)*100/len(LIST))\n",
    "print(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
